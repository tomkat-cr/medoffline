# MedOffLine ‚ú®

Asistente de IA Offline para Comunidades Remotas | üáªüá™ üá®üá¥

![Portada para la version en espa√±ol](./assets/MedOffLine-cover-image-final.png)

## Descripci√≥n

<img 
    align="right"
    width="100"
    height="100"
    src="./assets/MedOffLine.circled.logo.500.png"
    title="MedOffLine logo dise√±ado por Carlos J. Ramirez"
/>

MedOffLine es un Asistente de IA (Inteligencia Artificial) enfocado a ofrecer orientaci√≥n de primeros auxilios b√°sicos en comunidades con acceso limitado o sin acceso a Internet.

El sistema funciona en dispositivos m√≥viles Android de mediano costo y usa los [modelos ligeros Llama 3.2 1B/3B de Meta](https://www.llama.com/).

## El Problema

<img 
    align="right"
    width="100"
    height="100"
    src="./assets/67481623-2eba-4512-b106-4d25ddc30a75.jpeg"
    title="Imagen para el problema"
/>

El acceso a la salud es un desaf√≠o en comunidades rurales debido a:

* Conectividad limitada.
* Barreras geogr√°ficas.
* Escasez de servicios m√©dicos.

## Soluci√≥n

![Imagen para la solucion](./assets/MedOffLine-cover-image-1.webp)

MedOffLine ofrece una soluci√≥n 100% offline, ligera y culturalmente inclusiva, proporcionando.

* Gu√≠as de primeros auxilios.
* Diagn√≥sticos preliminares basados en s√≠ntomas.
* Informaci√≥n sobre medicamentos b√°sicos (dosis, efectos secundarios).
* Orientaci√≥n sobre cu√°ndo y d√≥nde buscar ayuda m√©dica.
* Material educativo sobre prevenci√≥n de enfermedades comunes.

## Impacto directo y medible

<img 
    align="left"
    width="100"
    height="100"
    src="./assets/4d7f3d04-622f-4f0b-bee2-ab0749ab551c.jpeg"
    title="Imagen para impacto directo y medible"
    style="padding-right: 5px"
/>

Se podr√≠a medir el impacto por el n√∫mero de personas atendidas, consultas realizadas y casos cr√≠ticos identificados.

Su implementaci√≥n podr√≠a reducir las complicaciones de salud prevenibles.
<BR/>
<BR/>

## Por qu√© este proyecto tiene alta viabilidad

<img 
    align="right"
    width="100"
    height="100"
    src="./assets/b9154955-edc2-4b3c-9124-d3c983b76d2c.jpeg"
    title="Imagen para por qu√© este proyecto tiene alta viabilidad"
/>

Uso eficiente de tecnolog√≠a:

* Llama 3.2 es ideal porque incluye modelos ligeros que pueden funcionar en dispositivos m√≥viles con recursos limitados, incluso sin conexi√≥n a internet.

Escalabilidad:

* Puede ampliarse a otros pa√≠ses o regiones con desaf√≠os similares.

* Podr√≠a traducirse a lenguas ind√≠genas o adaptarse a contextos espec√≠ficos.

Viabilidad t√©cnica y econ√≥mica:

* No requiere hardware sofisticado ni infraestructura costosa.

* Puede financiarse mediante asociaciones con ONGs, gobiernos locales o iniciativas de salud p√∫blica.

## Uso

1. Entrar en el sitio web: [https://medoffline.streamlit.app](https://medoffline.streamlit.app)<BR/><BR/>
   ![MedOffline langing page](./assets/screenshots/Screenshot%202024-11-25%20at%201.25.27‚ÄØPM.png)

2. Hacer clic en el bot√≥n Descargar APK.

3. Esperar que la descarga termine.

4. Ir a **Descargas** en el men√∫ del navegador y tocar el archivo medoffline.apk.

5. Buscar el icono de la App **MedOffline** y tocarlo.

6. La primera vez la App har√° la descarga del modelo inicial, lo cual tomara cerca de 3 minutos. Disculpe la espera ;)

7. Una vez terminada la descarga, aparece la pantalla principal con una interfaz de usuario tipo Chatbot.<BR/><BR/>
   ![App UI](./assets/screenshots/IMG_0732.jpeg)

## Tecnolog√≠a utilizada

* [Modelos de Meta Llama: 3.2 1B/3B, y 3.1 70B](https://www.llama.com/llama-downloads)
* [Pytorch Executorch](https://github.com/pytorch/executorch)
* [Java](https://developer.android.com/build/jdks)
* [Python](https://www.python.org)
* [Streamlit](https://streamlit.io)
* [Kaggle](https://www.kaggle.com/models/tomkatcr/llama3.2_3b_pte)
* [Github](https://github.com)

### Para el dise√±o gr√°fico y la programaci√≥n

* [Canva](https://www.canva.com/)
* [ChatGPT / Dall-E](https://chatgpt.com/)
* [Flux.1](https://flux-ai.io/)
* [Github Copilot](https://github.com/features/copilot)

## Contexto

Este proyecto fue desarrollado como parte del [Llama Impact Pan-LATAM Hackathon](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es) organizado por [Lablab.ai](https://lablab.ai).

![Hackathon banner image](./assets/hackathon-llama-impact-pan-latam-es-official-banner.webp) 

Submission page:

[https://lablab.ai/event/hackathon-llama-impact-pan-latam-es/the-fynbots/medoffline](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es/the-fynbots/medoffline)

Recursos:

* Sitio Web:<BR/>
  [https://medoffline.streamlit.app](https://medoffline.streamlit.app)

* C√≥digo Fuente:<BR/>
  [https://github.com/tomkat-cr/medoffline](https://github.com/tomkat-cr/medoffline)

* Modelos en Kaggle:<BR/>
  [https://www.kaggle.com/models/tomkatcr/llama3.2_3b_pte](https://www.kaggle.com/models/tomkatcr/llama3.2_3b_pte)

* Video-presentaci√≥n:<BR/>
  [https://youtu.be/R-rAKMbKVus?si=KbJgHZFg4J4f8BXX](https://youtu.be/R-rAKMbKVus?si=KbJgHZFg4J4f8BXX)

* Documento de la presentaci√≥n: [PDF](https://storage.googleapis.com/lablab-static-eu/presentations/submissions/cm3xdpe8l00113b713e90gmb5/cm3xdpe8l00113b713e90gmb5-1732561102890_zq1alr0cwl.pdf)

* P√°gina del equipo: [The FynBots](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es/the-fynbots)

## El Equipo de Trabajo

[The FynBots](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es/the-fynbots)

![Imagen de los FynBots 2024-11-25](./assets/The.FynBots.2024-11-25.IMG_0749.jpg)

* Omar Tob√≥n | [Linkedin](https://www.linkedin.com/in/omar-tobon) | üá®üá¥ | Creativo, coach.<BR/><BR/>
  Generaci√≥n de la idea, generaci√≥n IA de im√°genes, desarrollo del namimg, curadur√≠a de datasets para fine-tuning de modelos, dise√±o y producci√≥n de la presentaci√≥n, manejo de la inteligencia emocional y coaching del equipo.

* Carlos J. Ram√≠rez | [Linkedin](https://www.linkedin.com/in/carlosjramirez) | üáªüá™ | Arquitecto de software, l√≠der t√©cnico.<BR/><BR/>
  Codificaci√≥n del prototipo para Android, conversion de los modelos Llama 3.2 al formato de Pytorch Executor (`.pte`), publicaci√≥n de los modelos en Kaggle, dise√±o del sitio web, despliegue de la aplicaci√≥n y el sitio web, manejo del equipo en la plataforma de lablab.ai, producci√≥n de la video-presentaci√≥n. 

<BR/>
<hr>
<hr>
<BR/>

# MedOffLine ‚ú®

**Offline AI Assistant for Remote Communities | üáªüá™ üá®üá¥**

![Cover image for english version](./assets/1eb5de0b-c739-4547-920f-14d35f875db0.jpeg)

## Description

<img 
    align="right"
    width="100"
    height="100"
    src="./assets/MedOffLine.circled.logo.500.png"
    title="MedOffLine logo designed by Carlos J. Ramirez"
/>

MedOffLine is an AI Assistant designed to provide basic first aid guidance in communities with limited or no Internet access.

The system runs on mid-range Android mobile devices and uses [Meta's lightweight Llama 3.2 1B/3B models](https://www.llama.com/).

## The Problem

<img 
    align="right"
    width="100"
    height="100"
    src="./assets/8bdffc8e-b8f0-4f9a-a883-dd7bcb70b3a6.jpeg"
    title="Image illustrating the problem"
/>

Access to healthcare is a challenge in rural communities due to:

* Limited connectivity.
* Geographic barriers.
* Scarcity of medical services.

## Solution

![Image illustrating the solution](./assets/MedOffLine-cover-image-1.webp)

MedOffLine offers a 100% offline, lightweight, and culturally inclusive solution, providing:

* First aid guides.
* Preliminary diagnostics based on symptoms.
* Information on basic medications (dosages, side effects).
* Guidance on when and where to seek medical help.
* Educational material on preventing common diseases.

## Direct and Measurable Impact

<img 
    align="left"
    width="100"
    height="100"
    src="./assets/4d7f3d04-622f-4f0b-bee2-ab0749ab551c.jpeg"
    title="Image illustrating measurable impact"
    style="padding-right: 5px"
/>

Impact can be measured by the number of people assisted, consultations performed, and critical cases identified.

Its implementation could reduce preventable health complications.
<BR/>
<BR/>

## Why This Project is Highly Viable

<img 
    align="right"
    width="100"
    height="100"
    src="./assets/f8938201-f228-4a65-82da-d5bfd52b5b6d.jpeg"
    title="Image illustrating high viability"
/>

**Efficient Use of Technology**:
* Llama 3.2 is ideal because it includes lightweight models capable of running on resource-limited mobile devices, even offline.

**Scalability**:
* It can be expanded to other countries or regions facing similar challenges.
* It could be translated into indigenous languages or adapted to specific contexts.

**Technical and Economic Feasibility**:
* Does not require sophisticated hardware or expensive infrastructure.
* Can be funded through partnerships with NGOs, local governments, or public health initiatives.

## Usage

1. Visit the website: [https://medoffline.streamlit.app](https://medoffline.streamlit.app)<BR/><BR/>
   ![MedOffline english landing page](./assets/screenshots/Screenshot%202024-11-27%20at%206.13.33%E2%80%AFAM.png)

2. Click the **English** button.

3. Click the **Download APK** button.

4. Wait for the download to complete.

5. Go to **Downloads** in the browser menu and tap the **medoffline.apk** file.

6. Look for the **MedOffline** App icon and tap it.

7. The first time, the App will download the initial model, which will take about 3 minutes. We apologize for the wait ;)

8. Once the download is complete, the main screen with a chatbot-style user interface will appear.<BR/><BR/>
   ![App UI](./assets/screenshots/IMG_0732.jpeg)

## Technology Used

* [Meta's Llama Models: 3.2 1B/3B, and 3.1 70B](https://www.llama.com/llama-downloads)
* [Pytorch Executorch](https://github.com/pytorch/executorch)
* [Java](https://developer.android.com/build/jdks)
* [Python](https://www.python.org)
* [Streamlit](https://streamlit.io)
* [Kaggle](https://www.kaggle.com/models/tomkatcr/llama3.2_3b_pte)
* [Github](https://github.com)

### For graphic design and coding

* [Canva](https://www.canva.com/)
* [ChatGPT / Dall-E](https://chatgpt.com/)
* [Flux.1](https://flux-ai.io/)
* [Github Copilot](https://github.com/features/copilot)

## Context

This project was developed as part of the [Llama Impact Pan-LATAM Hackathon](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es) organized by [Lablab.ai](https://lablab.ai).

![Hackathon banner image](./assets/hackathon-llama-impact-pan-latam-es-official-banner.webp) 

Submission page:
[https://lablab.ai/event/hackathon-llama-impact-pan-latam-es/the-fynbots/medoffline](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es/the-fynbots/medoffline)

Resources:

* Website:<BR/>
  [https://medoffline.streamlit.app](https://medoffline.streamlit.app)

* Source Code:<BR/>
  [https://github.com/tomkat-cr/medoffline](https://github.com/tomkat-cr/medoffline)

* Models on Kaggle:<BR/>
  [https://www.kaggle.com/models/tomkatcr/llama3.2_3b_pte](https://www.kaggle.com/models/tomkatcr/llama3.2_3b_pte)

* Video Presentation:<BR/>
  [https://youtu.be/R-rAKMbKVus?si=KbJgHZFg4J4f8BXX](https://youtu.be/R-rAKMbKVus?si=KbJgHZFg4J4f8BXX)

* Presentation document: [PDF](https://storage.googleapis.com/lablab-static-eu/presentations/submissions/cm3xdpe8l00113b713e90gmb5/cm3xdpe8l00113b713e90gmb5-1732561102890_zq1alr0cwl.pdf)

* Team page: [The FynBots](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es/the-fynbots)

## The Team

[The FynBots](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es/the-fynbots)

![FynBots team image 2024-11-25](./assets/The.FynBots.2024-11-25.IMG_0749.jpg)

* **Omar Tob√≥n** | [Linkedin](https://www.linkedin.com/in/omar-tobon) | üá®üá¥ | Creative, coach.<BR/><BR/>
  Idea generation, AI image generation, naming development, curation of datasets for model fine-tuning, presentation design and production, emotional intelligence management, and team coaching.

* **Carlos J. Ram√≠rez** | [Linkedin](https://www.linkedin.com/in/carlosjramirez) | üáªüá™ | Software architect, technical leader.<BR/><BR/>
  Prototype coding for Android, conversion of Llama 3.2 models to Pytorch Executor format (`.pte`), publication of models on Kaggle, website design, application and website deployment, team management on the lablab.ai platform, video presentation production.

<BR/>
<hr>
<hr>
<BR/>

## Getting Started

### Prerequisites

- [Python](https://www.python.org/downloads/) 3.10 or higher
- [Git](https://www.atlassian.com/git/tutorials/install-git)
- Make: [Mac](https://formulae.brew.sh/formula/make) | [Windows](https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows)
- [Android Studio](https://developer.android.com/studio)

For the model fine-tune:

- [Conda](https://anaconda.org/anaconda/conda)
- [Java 17 JDK](https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html)
- [Android SDK API Level 34](https://developer.android.com/about/versions/15/setup-sdk)
- [Android NDK r27b](https://github.com/android/ndk/releases/tag/r27b)
- [Kaggle account](https://www.kaggle.com)
- [Meta Llama models](https://www.llama.com/llama-downloads)
- [Hugging Face account](https://huggingface.co)
- A PC with enough resources. We used one with a Gigabyte GeForce RTX 4060, 32 GB RAM, AMD Ryzen 7 5700X.

### Installation

Clone the repository:
```bash
git clone https://github.com/tomkat-cr/medoffline.git
```

Navigate to the project directory:

```bash
cd medoffline
```

- The website sources can be found in the [public](./public/) directory.

- The Android applicacion can be opened in Android Studio from the directory [android/MedOffLine](./android/MedOffLine)

- The AI Model used in the Android app can be found in [Kaggle](https://www.kaggle.com/models/tomkatcr/llama3.2_3b_pte).

- The Model was generated following these instructions:

1. Follow the instructions to install Executorch on your computer:
    * [https://github.com/pytorch/executorch/tree/main/examples/models/llama#step-1-setup](https://github.com/pytorch/executorch/tree/main/examples/models/llama#step-1-setup)
    * [https://github.com/pytorch/executorch/tree/main/examples/models/llama#step-3-run-on-your-computer-to-validate](https://github.com/pytorch/executorch/tree/main/examples/models/llama#step-3-run-on-your-computer-to-validate)

2. Download the Llama 3.2 lightweight model and tokenizer from [the Meta Llama website](https://www.llama.com/llama-downloads) and copy it to a local directory, e.g. `/home/username/.llama/checkpoints`.

3. Create the output directory, e.g. `/home/username/llama_models`.

4. Convert the model to `.pte` format:

```bash
LLAMA_CHECKPOINT="/home/username/.llama/checkpoints/Llama3.2-3B-Instruct/consolidated.00.pth"
LLAMA_PARAMS="/home/username/.llama/checkpoints/Llama3.2-3B-Instruct/params.json"
OUTPUT_FILE="/home/username/llama_models/llama32_3b_4096_kv_sdpa_xnn_qe_4_32.pte"
MAX_SEQ_LENGTH="4096"

python -m examples.models.llama.export_llama \
    --checkpoint $LLAMA_CHECKPOINT \
	-p $LLAMA_PARAMS \
	-kv \
	--use_sdpa_with_kv_cache \
	-X \
	-qmode 8da4w \
	--group_size 128 \
	--max_seq_length $MAX_SEQ_LENGTH \
	-d fp32 \
	--metadata '{"get_bos_id":128000, "get_eos_ids":[128009, 128001]}' \
	--embedding-quantize 4,32 \
	--output_name $OUTPUT_FILE
```

5. Test the `.pte` model:

```bash
PTE_MODELS_PATH="/home/username/llama_models"
TOKENIZER_MODEL="$PTE_MODELS_PATH/tokenizer.model"
PTE_SOURCE_FILE="$PTE_MODELS_PATH/llama32_3b_4096_kv_sdpa_xnn_qe_4_32.pte"
PROMPT="What the the capital of France?"

cmake-out/examples/models/llama/llama_main --model_path="$PTE_SOURCE_FILE" --tokenizer_path="$TOKENIZER_MODEL" --prompt="$PROMPT"
```

<!--
### Create the .env file

Create a `.env` file in the root directory of the project:

```bash
# You can copy the .env.example file in the root directory of the project
cp .env.example .env
```

The `.env` file should have the following content:

```bash
PYTHON_VERSION=3.10
#
# Together AI
TOGETHER_AI_API_KEY=
# OpenAI
OPENAI_API_KEY=
#
# Database parameters
DB_TYPE=mongodb
# DB_TYPE=json
#
# MongoDB database parameters
MONGODB_URI=mongodb+srv://<user>:<password>@<cluster>.mongodb.net
MONGODB_DB_NAME=MedOffLine-dev
#
# JSON database parameters
# JSON_DB_PATH=./db/conversations.json
```

Replace `TOGETHER_AI_API_KEY` and other access tokens with your actual Together.ai API key, OpenAI, Huggingface, Groq, Nvidia, and Rhymes API keys, respectively.

To use a MongoDB database, comment out `DB_TYPE=json`, uncomment `# DB_TYPE=mongodb`, and replace `YOUR_MONGODB_URI`, `YOUR_MONGODB_DB_NAME`, and `YOUR_MONGODB_COLLECTION_NAME` with your actual MongoDB URI, database name, and collection name, respectively.
-->

### Run the Streamlit application

```bash
# With Make
make run
```

```bash
# Without Make
sh ./public/scripts/run_app.sh run
```

### Streamlit application usage

Go to your favorite Browser and open the URL provided by the application.

* Locally:<BR/>
  [http://localhost:8503/](http://localhost:8503/)

* Official App:<BR/>
  [https://medoffline.streamlit.app/](https://MedOffLine.streamlit.app/)

## Contributors

[Carlos J. Ramirez](https://www.linkedin.com/in/carlosjramirez/) | [Omar Tobon](https://www.linkedin.com/in/omar-tobon/)

Please feel free to suggest improvements, report bugs, or make a contribution to the code.

## License

This project is licensed under the terms of the MIT license. See the [LICENSE](LICENSE) file for details.

## Acknowledgements

* [AI at Meta](https://ai.meta.com/) for developing the Llama powerful models and technology.
* [Lablab.ai](https://lablab.ai) for organizing the [Llama Impact Pan-LATAM Hackathon](https://lablab.ai/event/hackathon-llama-impact-pan-latam-es).
* Open-source community for inspiring and supporting collaborative innovation.
* Users and contributors for their feedback and support.

<BR/><BR/>
<center>

![MedOffLine logo](./assets/MedOffLine.circled.logo.500.png)

</center>

